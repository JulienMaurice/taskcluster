---
title: Monitoring Services
---
import SiteSpecific from 'taskcluster-ui/components/SiteSpecific';
import Image from 'taskcluster-ui/views/Documentation/Image'
import telescopeDiagram from './telescope-diagram.svg'

# Monitoring Services

## New Relic

Taskcluster services *optionally* support New Relic.
To enable this support, add a top-level Helm property named `newRelic` containing a JSON object with [New Relic environment variables](https://docs.newrelic.com/docs/agents/nodejs-agent/installation-configuration/nodejs-agent-configuration) and their values.
This will be distributed to all services.

```yaml
newRelic:
  NEW_RELIC_APP_NAME: my-app
  NEW_RELIC_LICENSE_KEY: 12345
  # ...
```

## Background Processes

Taskcluster has several background processes that you should ensure are running on a schedule. Any of the following will generate messages
of the form:

```json
{
  "Type": "monitor.periodic",
  "Logger": "<Logger>",
  "Fields": {
    "name": "<Name>"
  }
}
```

They will also have Fields for `status`, `duration`, and a serialized `error` if an error occured.

The processes that have `continuous` for their deadline and schedule run every few minutes and should complete fairly quickly. The rest
have their schedules and maximum allowed duration defined here. All times are relative to the timezone of the k8s cluster.

<!-- BEGIN MONITORING TABLE -->
| Service        | Name                         | Logger                     | Deadline (seconds) | Schedule                    |
| -------------- | ---------------------------- | -------------------------- | ------------------ | --------------------------- |
| auth           | purgeExpiredClients          | taskcluster.auth           | 86400              | At 12:00 AM                 |
| github         | sync                         | taskcluster.github         | 86400              | At 12:00 AM                 |
| hooks          | expires                      | taskcluster.hooks          | 86400              | At 12:10 AM                 |
| index          | expire                       | taskcluster.index          | 86400              | At 12:00 AM                 |
| object         | expire                       | taskcluster.object         | 86400              | At 12:00 AM                 |
| purge-cache    | expireCachePurges            | taskcluster.purge-cache    | 86400              | At 12:00 AM                 |
| queue          | claimResolver                | taskcluster.queue          | continuous         | continuous                  |
| queue          | deadlineResolver             | taskcluster.queue          | continuous         | continuous                  |
| queue          | dependencyResolver           | taskcluster.queue          | continuous         | continuous                  |
| queue          | expireArtifacts              | taskcluster.queue          | 86400              | At 12:00 AM                 |
| queue          | expireTask                   | taskcluster.queue          | 86400              | At 12:00 AM                 |
| queue          | expireTaskGroups             | taskcluster.queue          | 86400              | At 12:00 AM                 |
| queue          | expireTaskDependency         | taskcluster.queue          | 86400              | At 12:00 AM                 |
| queue          | expireQueueMessages          | taskcluster.queue          | 3600               | At 23 minutes past the hour |
| queue          | expireWorkerInfo             | taskcluster.queue          | 86400              | At 12:00 AM                 |
| secrets        | expire                       | taskcluster.secrets        | 600                | Every hour                  |
| web-server     | scanner                      | taskcluster.web-server     | 86400              | At 12:00 AM                 |
| web-server     | cleanup-expire-auth-codes    | taskcluster.web-server     | 86400              | At 12:00 AM                 |
| web-server     | cleanup-expire-access-tokens | taskcluster.web-server     | 86400              | At 12:00 AM                 |
| worker-manager | provisioner                  | taskcluster.worker-manager | continuous         | continuous                  |
| worker-manager | workerscanner                | taskcluster.worker-manager | continuous         | continuous                  |
| worker-manager | expire-workers               | taskcluster.worker-manager | 86400              | At 12:00 AM                 |
| worker-manager | expire-worker-pools          | taskcluster.worker-manager | 86400              | At 01:00 AM                 |
| worker-manager | expire-errors                | taskcluster.worker-manager | 86400              | At 12:10 AM                 |
<!-- END MONITORING TABLE -->

## Telescope

Taskcluster supports being monitored by [Telescope](https://github.com/mozilla-services/telescope).

### Image

This is an svg image generated for use in the Telescope UI. Download it and read the Telescope
documentation for how to use it. It is designed to work with the config below.

<Image src={telescopeDiagram} />

### Configuration

For this deployment of Taskcluster, a config file may look as follows:

<SiteSpecific>
Simply replace `EXAMPLE.COM` with your rootUrl (in this case %root_url%).
</SiteSpecific>

<!-- BEGIN POUCAVE CONFIG -->
```toml
[checks.taskcluster.auth-heartbeat]
description = "auth service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/auth/v1/ping"

[checks.taskcluster.github-heartbeat]
description = "github service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/github/v1/ping"

[checks.taskcluster.hooks-heartbeat]
description = "hooks service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/hooks/v1/ping"

[checks.taskcluster.index-heartbeat]
description = "index service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/index/v1/ping"

[checks.taskcluster.notify-heartbeat]
description = "notify service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/notify/v1/ping"

[checks.taskcluster.object-heartbeat]
description = "object service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/object/v1/ping"

[checks.taskcluster.purge-cache-heartbeat]
description = "purge-cache service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/purge-cache/v1/ping"

[checks.taskcluster.queue-heartbeat]
description = "queue service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/queue/v1/ping"

[checks.taskcluster.secrets-heartbeat]
description = "secrets service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/secrets/v1/ping"

[checks.taskcluster.web-server-heartbeat]
description = "web-server service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/web-server/v1/ping"

[checks.taskcluster.worker-manager-heartbeat]
description = "worker-manager service is alive"
module = "checks.core.heartbeat"
ttl = 60
"params.url" = "https://EXAMPLE.COM/api/worker-manager/v1/ping"

```
<!-- END POUCAVE CONFIG -->
